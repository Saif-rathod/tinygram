{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT ---> Generatively Pretrained Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text:  1115394\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(\"Length of the text: \", len(text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)} #mapping from character to integers\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s:[stoi[c] for c in s] #encoding the text into integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) #decoding the integers back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 47, 47, 1, 26, 47, 45, 45, 39]\n",
      "Hii Saif\n"
     ]
    }
   ],
   "source": [
    "print (encode(\"Hii Saif\"))\n",
    "print(decode(encode(\"Hii Saif\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data [:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]) the target: 47\n",
      "When input is tensor([18, 47]) the target: 56\n",
      "When input is tensor([18, 47, 56]) the target: 57\n",
      "When input is tensor([18, 47, 56, 57]) the target: 58\n",
      "When input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'When input is {context} the target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size + 1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is[24] the target: 43\n",
      "when input is[24, 43] the target: 58\n",
      "when input is[24, 43, 58] the target: 5\n",
      "when input is[24, 43, 58, 5] the target: 57\n",
      "when input is[24, 43, 58, 5, 57] the target: 1\n",
      "when input is[24, 43, 58, 5, 57, 1] the target: 46\n",
      "when input is[24, 43, 58, 5, 57, 1, 46] the target: 43\n",
      "when input is[24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
      "when input is[44] the target: 53\n",
      "when input is[44, 53] the target: 56\n",
      "when input is[44, 53, 56] the target: 1\n",
      "when input is[44, 53, 56, 1] the target: 58\n",
      "when input is[44, 53, 56, 1, 58] the target: 46\n",
      "when input is[44, 53, 56, 1, 58, 46] the target: 39\n",
      "when input is[44, 53, 56, 1, 58, 46, 39] the target: 58\n",
      "when input is[44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is[52] the target: 58\n",
      "when input is[52, 58] the target: 1\n",
      "when input is[52, 58, 1] the target: 58\n",
      "when input is[52, 58, 1, 58] the target: 46\n",
      "when input is[52, 58, 1, 58, 46] the target: 39\n",
      "when input is[52, 58, 1, 58, 46, 39] the target: 58\n",
      "when input is[52, 58, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is[52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
      "when input is[25] the target: 17\n",
      "when input is[25, 17] the target: 27\n",
      "when input is[25, 17, 27] the target: 10\n",
      "when input is[25, 17, 27, 10] the target: 0\n",
      "when input is[25, 17, 27, 10, 0] the target: 21\n",
      "when input is[25, 17, 27, 10, 0, 21] the target: 1\n",
      "when input is[25, 17, 27, 10, 0, 21, 1] the target: 54\n",
      "when input is[25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'when input is{context.tolist()} the target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xb) #input to the transformer\n",
    "print(yb), print(xb.shape), print(yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(5.0364, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "l-QYjt'CL?jLDuQcLzy'RIo;'KdhpV\n",
      "vLixa,nswYZwLEPS'ptIZqOZJ$CA$zy-QTkeMk x.gQSFCLg!iW3fO!3DGXAqTsq3pdgq\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding (vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self,idx, targets = None):\n",
    "        \n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            logits, loss = self(idx)\n",
    "            \n",
    "            logits = logits[: ,-1, :]\n",
    "            \n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            \n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "            \n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "            \n",
    "        return idx\n",
    "            \n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits , loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype = torch.long), max_new_tokens = 100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0514681339263916\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    \n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MurkoedMyasstocondad.e-mNSInsso&bF o&$;BRjlootZEOK:\n",
      ";DREm mpenPES:HUCARfounqCEyoAR:ZEN:VhmrdajCAbeSpr ue.HQNGJGefpostrer bk.hpENUCoeldalErPtshenoefeseards:\n",
      "ARW3ENGXURDUCI n ckcexpyV&jonnd,s,notor owarCInsXElrPjesV.butrPOZEMIh a hToANIZK:Y kpr ierPoEEQUENP?WNGl?oYopig;ENoV3q&jom.L; ik,\n",
      "Thwayore,er fyYWitJUCay ma O?AqV-\n",
      "MoivL\n",
      "OREzX3Dor,EL.xy\n",
      "Th r ss myoM:\n",
      " pZrAQll'vPOutezN\n",
      "BPe3mo'RMqFhePOxYenY utek,-ZEFFLar agmoPensfoXh hUCoPAQwn.QUFayestywNod p bGPopAllllernqDGudDUP.JaravVDofIxx.c whooraDivRS:\n",
      ";F\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype = torch.long ), max_new_tokens = 500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b =\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c =\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1 , keepdim = True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print('a =')\n",
    "print(a)\n",
    "print('b =')\n",
    "print(b)\n",
    "\n",
    "print('c =')\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337) #toy example\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C)) #bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow[b,t] = torch.mean(xprev,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T,T)) #tril --> lower triangular ones value tensor\n",
    "wei = wei / wei.sum(1, keepdim = True)\n",
    "xbow2 = wei @ x #(B,T,T) @ (B,T,C) --> (B,T,C)\n",
    "torch.allclose(xbow, xbow2, atol=1e-6, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]),\n",
       " tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T)) #using Softmax\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float ('-inf'))\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T)) #using Softmax\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float ('-inf'))\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3, atol=1e-6, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#self attention\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "value = nn.Linear(C, head_size, bias = False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "\n",
    "wei = q @ k.transpose(-2,-1)    # (B,T,H=16) @ (B,H=16,T) --> (B,T,T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float ('-inf'))\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
       "        [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
       "        [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size ** -0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1,-0.2, 0.3, -0.2, 0.5]), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]) * 8, dim= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8509, 0.1491]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(1,2)\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d:\n",
    "    \n",
    "    def __init__(self, dim, eps= 1e-5, momentum = 0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        xmean = x.mean(1, keepdim = True)\n",
    "        xvar = x.var(1, keepdim = True)\n",
    "        \n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "\n",
    "        return self.out \n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "    \n",
    "    \n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100)\n",
    "x = module(x)\n",
    "x.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1335, -0.1059, -0.3824,  ..., -1.3422, -0.1971,  0.8795],\n",
       "        [-0.0353, -0.7439, -0.3371,  ..., -0.6276, -0.4846,  0.4556],\n",
       "        [ 0.3069, -1.5010,  1.4898,  ..., -0.6819,  0.9993,  0.8382],\n",
       "        ...,\n",
       "        [-1.6080, -1.6324, -0.7634,  ..., -0.9847,  0.0039, -0.8610],\n",
       "        [-0.2273,  0.0066, -0.2763,  ..., -0.8705, -1.2442, -0.7531],\n",
       "        [ 0.3054, -0.1505, -0.3809,  ..., -1.4962, -0.7711, -1.0681]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209729 M\n",
      "step0: train loss 4.7080, val loss 4.7021\n",
      "step100: train loss 2.5367, val loss 2.5498\n",
      "step200: train loss 2.4032, val loss 2.4125\n",
      "step300: train loss 2.3252, val loss 2.3371\n",
      "step400: train loss 2.2415, val loss 2.2425\n",
      "step500: train loss 2.1825, val loss 2.1859\n",
      "step600: train loss 2.1178, val loss 2.1228\n",
      "step700: train loss 2.0572, val loss 2.0565\n",
      "step800: train loss 2.0222, val loss 2.0144\n",
      "step900: train loss 1.9816, val loss 1.9828\n",
      "step1000: train loss 1.9813, val loss 1.9729\n",
      "step1100: train loss 1.9366, val loss 1.9362\n",
      "step1200: train loss 1.8885, val loss 1.8886\n",
      "step1300: train loss 1.8653, val loss 1.8594\n",
      "step1400: train loss 1.8571, val loss 1.8556\n",
      "step1500: train loss 1.8388, val loss 1.8178\n",
      "step1600: train loss 1.7931, val loss 1.7902\n",
      "step1700: train loss 1.7879, val loss 1.7792\n",
      "step1800: train loss 1.7697, val loss 1.7605\n",
      "step1900: train loss 1.7624, val loss 1.7603\n",
      "step2000: train loss 1.7408, val loss 1.7445\n",
      "step2100: train loss 1.7299, val loss 1.7241\n",
      "step2200: train loss 1.7176, val loss 1.7142\n",
      "step2300: train loss 1.6871, val loss 1.6967\n",
      "step2400: train loss 1.6850, val loss 1.6782\n",
      "step2500: train loss 1.6744, val loss 1.6613\n",
      "step2600: train loss 1.6536, val loss 1.6644\n",
      "step2700: train loss 1.6381, val loss 1.6450\n",
      "step2800: train loss 1.6433, val loss 1.6379\n",
      "step2900: train loss 1.6245, val loss 1.6415\n",
      "step3000: train loss 1.6208, val loss 1.6207\n",
      "step3100: train loss 1.6234, val loss 1.6083\n",
      "step3200: train loss 1.6014, val loss 1.6086\n",
      "step3300: train loss 1.5955, val loss 1.6025\n",
      "step3400: train loss 1.5978, val loss 1.5926\n",
      "step3500: train loss 1.5752, val loss 1.5733\n",
      "step3600: train loss 1.5673, val loss 1.5806\n",
      "step3700: train loss 1.5625, val loss 1.5618\n",
      "step3800: train loss 1.5675, val loss 1.5654\n",
      "step3900: train loss 1.5562, val loss 1.5444\n",
      "step4000: train loss 1.5473, val loss 1.5398\n",
      "step4100: train loss 1.5481, val loss 1.5341\n",
      "step4200: train loss 1.5265, val loss 1.5317\n",
      "step4300: train loss 1.5209, val loss 1.5255\n",
      "step4400: train loss 1.5063, val loss 1.5159\n",
      "step4500: train loss 1.5139, val loss 1.5065\n",
      "step4600: train loss 1.5081, val loss 1.5085\n",
      "step4700: train loss 1.4986, val loss 1.5126\n",
      "step4800: train loss 1.4796, val loss 1.4914\n",
      "step4900: train loss 1.4974, val loss 1.4878\n",
      "step4999: train loss 1.4842, val loss 1.4824\n",
      "\n",
      "As bready infup the weet Lucen.\n",
      "\n",
      "SEBASTIAN:\n",
      "' failous reped it worly, his but two slave you Lavic!\n",
      "\n",
      "ALONSO:\n",
      "I say? should! now on, I will? now!\n",
      "\n",
      "Padeda' to the gere great? you fathas of the Jescems,\n",
      "And her keeply, Velwat! bided more that Tunand word out.\n",
      "\n",
      "TRANIO:\n",
      "Why, thou's burn born repsucias, as telp,\n",
      "Art do qualiticies, of marrechio\n",
      "Treger queliest to her, if Now, hat thou you\n",
      "Or make of prodid, old as abhort,\n",
      "And that is the note. Graid syir?\n",
      "\n",
      "TRANIO:\n",
      "All here's come honce\n",
      "More is come from Me lapped of the make eace!\n",
      "\n",
      "PROSPERO:\n",
      "Come.\n",
      "\n",
      "Tellam'd marring, give of the hie to be tommorel.\n",
      "\n",
      "PETRUCHIO:\n",
      "This unking me. madst my hore she witter marries more.\n",
      "\n",
      "PROSPERO:\n",
      "What, jounce! and to welcome of\n",
      "enorce! would name, if in met and hages and wido, berrem'd or fies one her list?\n",
      "\n",
      "SEBASTIAN:\n",
      "Narter if thou see! Kate, minet's foom one ritign, new his it;\n",
      "Our contented; Katharina;' will cowe, Gentlemen,\n",
      "Migzomfer o' thy house as lipain is it of my beliel:\n",
      "The deapon you': him his below doweli go of reade an\n",
      "of the gene your her wate all el.\n",
      "\n",
      "LUCENTIO:\n",
      "For sen't is be so: I'll sure daughter hom\n",
      "After thy lant, son!\n",
      "Now, thou; Kate: she out not.\n",
      "\n",
      "TRANIO:\n",
      "And you the dartimes o' of heer doth\n",
      "With he plineserp is would done with musicles!\n",
      ".\n",
      "\n",
      "BAPTISTA:\n",
      "Go templew's foul help as round\n",
      "Is servike to do, I ho! she's made her.\n",
      "\n",
      "LUCENTIO:\n",
      "How thou naw'st?\n",
      "\n",
      "Nate coms, sir:\n",
      "The's horse conce! arry, I'll that will mad thing to more out\n",
      "Which no, old thy ling infery 'Prifruca.\n",
      "Hy will next they book to sop, Sored in one it netree masse to hearst\n",
      "That be aprody Kate, buch meaning in helper Greemi,' creet to me water,\n",
      "Nay, cheroous that pinceses to scompudy,\n",
      "To poes, you horse make you me, look fool her lanqued.\n",
      "\n",
      "ANTONIO:\n",
      "For name, the cises as of is toake 'till.\n",
      "\n",
      "LUCENTIO:\n",
      "Nay, plebasioud; and gock Sin she chil? musicent now by hought, how he lord!\n",
      "\n",
      "TRANIO:\n",
      "Is tell not couse; and onzelurentone obthem\n",
      "need, buck anguain the kind were like so look a buat,\n",
      "And on my holdrelues it? first!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size = 16 #hyperparameters\n",
    "block_size = 32\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "with open('input.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "chars = sorted(list(set(text))) \n",
    "vocab_size = len(chars)\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i , ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s:[stoi[c] for c in s]\n",
    "decode = lambda l:''.join([itos[i] for i in l])\n",
    "\n",
    "#train and test splits\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    \n",
    "    data = train_data if split == 'split' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size + 1] for i in ix])   \n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "            \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) \n",
    "        wei = F.softmax(wei, dim=-1) \n",
    "        \n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_heads, head_size):   \n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])        \n",
    "        self.proj = nn.Linear(n_head * head_size, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear (n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)  \n",
    "    \n",
    "    def forward(self, idx, targets = None):\n",
    "        \n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx) #B,T,C\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=idx.device)) #T,C\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        y = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        \n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            \n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "        \n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M') #total parameters\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step{iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        \n",
    "    xb, yb = get_batch('train')\n",
    "    logits , loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "context = torch.zeros ((1, 1), dtype = torch.long, device = device)\n",
    "print(decode(m.generate(context, max_new_tokens= 2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 1.4906, val loss 1.4836\n",
      "step 100: train loss 1.4867, val loss 1.4840\n",
      "step 200: train loss 1.4869, val loss 1.4694\n",
      "step 300: train loss 1.4625, val loss 1.4762\n",
      "step 400: train loss 1.4688, val loss 1.4633\n",
      "step 500: train loss 1.4663, val loss 1.4619\n",
      "step 600: train loss 1.4596, val loss 1.4574\n",
      "step 700: train loss 1.4347, val loss 1.4591\n",
      "step 800: train loss 1.4396, val loss 1.4418\n",
      "step 900: train loss 1.4466, val loss 1.4373\n",
      "step 1000: train loss 1.4442, val loss 1.4306\n",
      "step 1100: train loss 1.3815, val loss 1.3897\n",
      "step 1200: train loss 1.3729, val loss 1.3727\n",
      "step 1300: train loss 1.3657, val loss 1.3628\n",
      "step 1400: train loss 1.3604, val loss 1.3556\n",
      "step 1500: train loss 1.3539, val loss 1.3496\n",
      "step 1600: train loss 1.3564, val loss 1.3639\n",
      "step 1700: train loss 1.3490, val loss 1.3492\n",
      "step 1800: train loss 1.3514, val loss 1.3450\n",
      "step 1900: train loss 1.3420, val loss 1.3464\n",
      "step 2000: train loss 1.3397, val loss 1.3418\n",
      "step 2100: train loss 1.3390, val loss 1.3324\n",
      "step 2200: train loss 1.3464, val loss 1.3334\n",
      "step 2300: train loss 1.3396, val loss 1.3368\n",
      "step 2400: train loss 1.3336, val loss 1.3258\n",
      "step 2500: train loss 1.3408, val loss 1.3395\n",
      "step 2600: train loss 1.3373, val loss 1.3379\n",
      "step 2700: train loss 1.3417, val loss 1.3376\n",
      "step 2800: train loss 1.3286, val loss 1.3276\n",
      "step 2900: train loss 1.3352, val loss 1.3366\n",
      "step 3000: train loss 1.3323, val loss 1.3335\n",
      "step 3100: train loss 1.3271, val loss 1.3301\n",
      "step 3200: train loss 1.3358, val loss 1.3310\n",
      "step 3300: train loss 1.3346, val loss 1.3410\n",
      "step 3400: train loss 1.3314, val loss 1.3325\n",
      "step 3500: train loss 1.3249, val loss 1.3292\n",
      "step 3600: train loss 1.3281, val loss 1.3325\n",
      "step 3700: train loss 1.3339, val loss 1.3347\n",
      "step 3800: train loss 1.3307, val loss 1.3322\n",
      "step 3900: train loss 1.3343, val loss 1.3332\n",
      "step 4000: train loss 1.3326, val loss 1.3287\n",
      "step 4100: train loss 1.3397, val loss 1.3265\n",
      "step 4200: train loss 1.3331, val loss 1.3406\n",
      "step 4300: train loss 1.3277, val loss 1.3366\n",
      "step 4400: train loss 1.3429, val loss 1.3393\n",
      "step 4500: train loss 1.3380, val loss 1.3320\n",
      "step 4600: train loss 1.3289, val loss 1.3350\n",
      "step 4700: train loss 1.3329, val loss 1.3272\n",
      "step 4800: train loss 1.3233, val loss 1.3263\n",
      "step 4900: train loss 1.3389, val loss 1.3322\n",
      "step 4999: train loss 1.3305, val loss 1.3272\n"
     ]
    }
   ],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.1)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        \n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "context = torch.zeros ((1, 1), dtype = torch.long, device = device)\n",
    "print(decode(m.generate(context, max_new_tokens= 2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PETRUCHIO:\n",
      "Why, here berry.\n",
      "\n",
      "GRUMIO:\n",
      "I will not be voth lif grue comed?\n",
      "\n",
      "SEBASTIAN:\n",
      "Have to thy dayswishous.\n",
      "\n",
      "GRUMIO:\n",
      "Ay, ravence the king afride and kind less.\n",
      "\n",
      "PETRUCHIO:\n",
      "I told my couns; sir, my canue.\n",
      "\n",
      "Pedant:\n",
      "Ay, I say, he met you visit with Kate bather?\n",
      "\n",
      "SEBASTIAN:\n",
      "Your mistrang, Lucentio's\n",
      "I than is numped to-day. Then out;\n",
      "And more here primal at you the sensin; one ar thranged assident.\n",
      "\n",
      "PROSPERO:\n",
      "'Tis I'll a dening to tle'p, as new that a call'd in me out my slap his the sister'd;\n",
      "Fiddle, beat from the waters losded and all the goes welcome for fade\n",
      "How us in this is nexing both.\n",
      "\n",
      "ARIEL:\n",
      "Would my takes. When is your evils,\n",
      "'Tis as here comes me dower! heere.\n",
      "\n",
      "KATHARINA:\n",
      "What's if the maintenious\n",
      "Efirmans merry master'd undo!\n",
      "\n",
      "KATHARINA:\n",
      "Then you, go long lood.\n",
      "\n",
      "KATHARINA:\n",
      "Petruchio, poor my worms, both upon,\n",
      "Milan, so that young good thy bate so reports offer: thy lack it a gear so charged;\n",
      "Then yet, all out ear usy?\n",
      "\n",
      "PETRUCHIO:\n",
      "Genth toast Le'cuon?\n",
      "If by any than to greed my son persicsannance.\n",
      "\n",
      "TRANIO:\n",
      "No.\n",
      "\n",
      "CALO:\n",
      "Sir, I purace say follow Grumio!\n",
      "\n",
      "GONZALO:\n",
      "My livy her hate, serve be\n",
      "Why terch, beat at deed, for thou way,\n",
      "Pedanturns changest is power: name, sir.\n",
      "\n",
      "PROSPERO:\n",
      "With courterfuest fried you and put well.\n",
      "\n",
      "TRANIO:\n",
      "Bid cheep Vincentio? Which now Kate\n",
      "Shall I pray none, Kathow, in hid mated.\n",
      "\n",
      "PETRUCHIO:\n",
      "Let it not?\n",
      "\n",
      "BAPTISTA:\n",
      "Know, nothing, ext is the duked the wimony which souse your campany,\n",
      "In dear, in a soilen, Naples, fetcuder;\n",
      "But befil, good Trave her, not awaked!\n",
      "\n",
      "BAPTISTA:\n",
      "How, pervisied within ce.\n",
      "\n",
      "SEBASTIAN:\n",
      "Speak, men you master mayster board; and behold\n",
      "But haves man him, but he wear Lucentio or Kate to is is to the bades.\n",
      "You lozed! flo! are mean\n",
      "Of of Calimon of one, Happark he's their hath such and the says.\n",
      "\n",
      "CURTIS:\n",
      "What, my stills, sir: goods! what seezu;\n",
      " he most that thy Ariel.\n",
      "Nut incendle-ringes; in aboaring,\n",
      "Katharina, and 'tis at,\n",
      "'Hicked, no ha, sir. Good my forrow.\n",
      "But Sido, gentle contentful like to the.\n",
      "\n",
      "PETRUCHIO:\n",
      "Which \n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros ((1, 1), dtype = torch.long, device = device)\n",
    "print(decode(m.generate(context, max_new_tokens= 2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
